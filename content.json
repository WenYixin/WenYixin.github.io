[{"title":"DF大数据竞赛之搜狗用户画像经验总结","date":"2017-01-17T05:04:18.870Z","path":"2017/01/17/DF大数据竞赛经验总结/","text":"2016 DataFountain 大数据精准营销之搜狗用户画像挖掘 参赛经验总结本文主要整理和记录了我个人的参赛经历以及其他队伍的解决方案。 参赛背景跨专业基础奇差菜鸡一枚，HNU计算机研一在读。起初会参赛是因为上课的时候老师介绍了这个比赛，说参加这个的同学可以不用做论文报告，就果断报名了。由于确实是初次接触机器学习方面的知识，所以完全是从零看书开始的，开始的时候确实够呛，完全不知道怎么下手，后来通过群里前辈的一些指导跟自己的摸索终于也算找到了比较常规的门道。成绩最好的时候是A榜69名(虽然最终是掉到B榜132),对自己来说还是比较满意的。 赛题简介业务背景：用户画像，即：用户的属性及偏好。在广告的精准投放中，根据用户的历史行为来反推用户的属性是一项基础技术。本次赛题即为根据搜狗用户在一段时间内的搜索词来预测用户的性别、年龄和教育水平 训练数据：5w个用户在某段时间内的搜索词以及相应的属性：性别、年龄和教育水平，注意有缺失值。 预测数据：5w个用户在某段时间的搜索词。 性别、年龄和教育水平分别有：2、6、6个标签。 数据集下载链接: http://pan.baidu.com/s/1sl8imlB 密码: y3xn 方案概述1.分词分词工具其实挺多的，不过最后还是随大流用的jieba分词。这里的具体做法是，把每个用户的搜索句一句一句单独分词并去除停用词，并将分词结果保存到文本train_corpus_2w_row.txt中。其实这里有一个细节我当时没管，就是题目中要求预测结果是不能有0(即未知)的，所以开始做数据预处理的时候分类0的数据是应该清理掉的，这是做题的时候一个不严谨的地方。 2.构建tfidf特征矩阵提取特征，转化成向量的一步。这里计算tfidf用的是sklearn的计算tfidf的包，矩阵的存储用的是scipy的稀疏矩阵。因为没有降维，所以当时的特征维度大概在35万维左右。本来是打算用PCA的，但是sklearn的PCA不支持稀疏矩阵=_,= 。而且降维的话，一般也是用于那种维度过于巨大(上亿)电脑内存不足无法处理的情况才使用的，而且往往不会使分类效果变好，甚至会差，35万*2万维的元素用稀疏存储完全足够，所以就没有做降维。当时老师上课的时候还提了一点，说可以自己提取额外的特征，譬如词性(搜索词是动词多还是名词多这种)、搜索句长度、标点符号的使用等等，当时对这个方法抱有疑问没有尝试，不过后来想想确实是可行的。 3.分类模型这一步主要是调sklearn的API，我来来回回尝试了好几个模型(svm,lr,sgdclassifier,bayes..)，这里出来效果最好的是svm，调参优化之后就得到了最终0.65958的成绩。在这之后又咨询了几方的优化意见，得出的结论是1.不要只用单个模型，可以尝试一下多模型结合，比如多模型投票、bagging、boosting、stacking等，事实上复赛高名次队伍也确实都是用了多模型。2.参加竞赛其实就是个体力活，要不断的有人来调参数，有机器来跑程序，通过不断的尝试试来提高那0.0几%的成绩。 其他高排名队伍的方案整理第5名队伍方案(颇有帮助)，博客地址1/博客地址2其实10月初最开始找做题思路的时候，问的一个前辈，他当时就跟我提了用word2vec这个事情，但是并没有告诉我应该怎么用，所以我当时一直很疑惑，既然有tfidf特征向量了，还要word2vec的词向量干什么。现在第5名团队的方案解决了我心中的这个疑问：word2vec到底怎么用。 word2vec简介 word2vec主要是把单词转化为实数向量，它是一种训练词向量的方法，它根据单词的上下文信息获得单词的分布式表达（Distributed Representation），是一种无监督方法。它可以把一个单词转换成向量形式，并可以找出与这个单词意思相近的词汇。 word2vec的应用 第一个问题：根据词向量，该如何表达一篇文档呢？假设某文档中含有N个单词，每个单词使用K维的词向量表示。有人可能会说，把词向量拼起来，将一个文档形式化为$N∗KN∗K$的向d不就ok了吗？这个策略本身没有问题，但是在一般的情况下（非一般情况，比如卷积神经网络，利用pooling层可以解决维度不一致问题）这种做法并不合适，因为 无法解决不同的文档长度所导致的维度不一致问题。因此，我们采用了如下方法，把单词向量加和求平均，这种做法是有道理的：如果某一个单词表达能力越强，加和求平均得到的向量就越偏向该单词向量所指方向。第二个问题：得到了文档在wv下的向量表达，又该如何使用呢？ 首先，我们认为把K维的WV向量直接拼接在S-TFIWF特征上不是一个好的策略，因为S-TFIWF特征具有高稀疏度、高维度的特点，与WV这种稠密的形式区别过大。回顾上文中介绍到的Stacking集成框架，我们把WV特征拼接在了stack的第二层中，举个栗子：如果第一层有20个分类器，WV的维度为K，那么第二层特征的维度就变为了：K+20K+20。 S-TFIWF+WV从特征词与词向量这两个角度完成了文档的表达。 其实感觉直接用w2v训练好的文档向量拿去模型里边分类也不是不可以的样子。 总结 1.相比使用卡方检验、信息增益等特征筛选方法，使用简单的词频筛选效果更好，原因未知 2.深度学习的威力巨大，前四名均在一定程度上的结合了神经网络(BPNN/CNN)，这样做的一大好处就是可以通过设置神经网络的共享层学到年龄、学历这两种属性的关联，避免了人工设计特征。 3.两点细节：①如果三个属性中至少有一个属性缺失，那么就放弃该样本，因为他们认为这样的样本是不可靠的。②提取TFIDF特征时，保留单个查询中的空格。 4.难点：①训练集部分标签缺失。这是为了模拟真实的业务情况，增加了难度。②训练样本质量。想象一种环境：在家庭中，多人共用一个搜狗账号进行搜索，这会导致搜索文本的内容与用户属性有偏差，数据中的*噪声很大。 第2名队伍方案，git地址 团队方案如下1.特征工程TFIDF特征：对分词后的用户搜索词列表计算TFIDF矩阵，并通过卡方检验筛选出Top10万维特征LDA特征：对分词后的用户搜索词列表以5为步长设置10~100的主题数目来训练LDA特征，通过连接得到用户向量Word2vec特征：利用word2vec模型对分词后的用户搜索词列表训练100维的词向量，把每个用户搜索词的词向量做均值得到用户向量Doc2vec特征：把分词后的用户搜索词列表当作一个文档，利用doc2vec模型训练100维的文档向量向量，得到用户向量统计型特征：统计用户搜索词数量、英文搜索词数量等2.模型level1：使用TFIDF特征stack方式用LR、LinearSVC、MNB、BNB（Navie Bayes）模型得到result1level2：使用result1和LDA、W2V、D2V和统计类型特征训练第二层模型，使用模型有CNN、XGBoost 第1名队伍方案，git地址 只有代码 结语一个多月下来感觉还是蛮有收获的，一方面是机器学习方面知识的入门，从基础概念到算法到实际应用；另一方面是熟悉了python；另外还结识了一些朋友，做报告的时候也是蛮有成就感的。不过不足的地方就是对于机器学习的算法原理还不太了解，大多数情况是在调现成的API，所以还需要花时间深入学习机器学习和数学知识。这次竞赛权当入门练手也确实是入门练手，下次再有这样的机会肯定要好好组个team，奔着拿奖冲名次的心态去参赛了。","tags":[{"name":"竞赛 机器学习 大数据","slug":"竞赛-机器学习-大数据","permalink":"https://wenyixin.github.io/tags/竞赛-机器学习-大数据/"}]},{"title":"这是一个跑的很快的记者的博客","date":"2016-12-27T08:32:23.910Z","path":"2016/12/27/置顶文章/","text":"12$ cnaive blog created successfully you've got +1s!","tags":[]}]